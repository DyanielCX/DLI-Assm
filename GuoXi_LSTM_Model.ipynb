{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DyanielCX/DLI-Assm/blob/main/GuoXi_LSTM_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import All Dependencies & Libraries"
      ],
      "metadata": {
        "id": "V3ilUof92hQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, json, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42); random.seed(42)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers, Input"
      ],
      "metadata": {
        "id": "bPHfEubo2tRf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "dxJ7GJHQG7Bp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oQ-0h0-WxNaZ"
      },
      "outputs": [],
      "source": [
        "# ---------- 1) Load dataset (GitHub) ----------\n",
        "GITHUB_CSV = \"https://raw.githubusercontent.com/DyanielCX/DLI-Assm/refs/heads/main/dataset_B_05_2020_1.csv\"\n",
        "raw = pd.read_csv(GITHUB_CSV)\n",
        "\n",
        "# Keep text + label for DL\n",
        "df = raw[[\"url\", \"status\"]].dropna().copy()\n",
        "df[\"url\"] = df[\"url\"].astype(str).str.lower()\n",
        "y = df[\"status\"].astype(int).values\n",
        "texts = df[\"url\"].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Character-level tokenization\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wjT6-2myrMK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok = Tokenizer(char_level=True, lower=True, filters=\"\")\n",
        "tok.fit_on_texts(texts)\n",
        "\n",
        "seqs = tok.texts_to_sequences(texts)\n",
        "lengths = np.array([len(s) for s in seqs])\n",
        "\n",
        "# Use 95th percentile as maxlen to avoid over-padding\n",
        "maxlen = int(np.percentile(lengths, 95))\n",
        "maxlen = max(maxlen, 64)          # safety floor\n",
        "print(f\"Max sequence length (95th pct): {maxlen}\")\n",
        "\n",
        "X = pad_sequences(seqs, maxlen=maxlen, padding=\"post\", truncating=\"post\")"
      ],
      "metadata": {
        "id": "boigQQTBrQP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adcf2821-9973-426a-c1d5-10a8c954db30"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sequence length (95th pct): 131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/Val/Test split\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vZchAYZJuMcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.10, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "vocab_size = len(tok.word_index) + 1\n",
        "print(\"Vocab size (chars):\", vocab_size)"
      ],
      "metadata": {
        "id": "7A5DRfMmuF3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48451f6-c9da-4101-ec50-9f6ae6fc974d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size (chars): 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build LSTM model"
      ],
      "metadata": {
        "id": "2pmtU2nPuQmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab, seq_len, emb_dim=64, lstm_units=64, lr=1e-3):\n",
        "    inp = layers.Input(shape=(seq_len,), dtype=\"int32\")\n",
        "    x = layers.Embedding(vocab, emb_dim, input_length=seq_len)(inp)\n",
        "    x = layers.Bidirectional(layers.LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2))(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = models.Model(inp, out)\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=lr),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_model(vocab_size, maxlen)\n",
        "\n",
        "es = callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
        "rlr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-5)\n"
      ],
      "metadata": {
        "id": "FrxtFViIuQ5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab27fc7-04ec-4e53-e59a-f4a8b77a9a12"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Train + measure time\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q_KblW2kuZoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.perf_counter()\n",
        "hist = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=256,\n",
        "    callbacks=[es, rlr],\n",
        "    verbose=1\n",
        ")\n",
        "t1 = time.perf_counter()\n",
        "train_time_minutes = (t1 - t0) / 60.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBRdQOoXuTrB",
        "outputId": "eff66cc3-4390-452a-b7c6-9cbeea3b88cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 672ms/step - accuracy: 0.6190 - loss: 0.6631 - val_accuracy: 0.7825 - val_loss: 0.5049 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 689ms/step - accuracy: 0.7551 - loss: 0.5302 - val_accuracy: 0.7727 - val_loss: 0.4868 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 695ms/step - accuracy: 0.7663 - loss: 0.5083 - val_accuracy: 0.7814 - val_loss: 0.4767 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 669ms/step - accuracy: 0.7741 - loss: 0.4946 - val_accuracy: 0.7880 - val_loss: 0.4709 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 712ms/step - accuracy: 0.7757 - loss: 0.4812 - val_accuracy: 0.7902 - val_loss: 0.4479 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m 8/33\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 682ms/step - accuracy: 0.7856 - loss: 0.4621"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "Wy-yJvYYug0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = time.perf_counter()\n",
        "y_proba = model.predict(X_test, batch_size=512).ravel()\n",
        "t3 = time.perf_counter()\n",
        "pred_time_ms_per_sample = ((t3 - t2) / len(X_test)) * 1000.0\n",
        "\n",
        "y_pred = (y_proba >= 0.5).astype(int)\n",
        "\n",
        "acc  = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "rec  = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1   = f1_score(y_test, y_pred, zero_division=0)\n",
        "auc  = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "print(\"\\n=== LSTM Test Metrics ===\")\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall   : {rec:.4f}\")\n",
        "print(f\"F1-score : {f1:.4f}\")\n",
        "print(f\"ROC-AUC  : {auc:.4f}\")\n",
        "print(f\"Train time (min)        : {train_time_minutes:.2f}\")\n",
        "print(f\"Prediction time (ms/sample): {pred_time_ms_per_sample:.2f}\\n\")\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n"
      ],
      "metadata": {
        "id": "9qx4R9cyuhCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Plot Confusion matrix (normalized) and Roc Curve\n"
      ],
      "metadata": {
        "id": "SNcbnQnpw3nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred, normalize=\"true\")\n",
        "plt.figure()\n",
        "plt.imshow(cm, interpolation=\"nearest\")\n",
        "plt.title(\"Normalized Confusion Matrix — LSTM\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, f\"{cm[i, j]:.2f}\", ha=\"center\", va=\"center\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
        "plt.title(\"ROC Curve — LSTM\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OUlrrwYSw4BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Save artifacts\n"
      ],
      "metadata": {
        "id": "iEFSBwBlUXUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUT = Path(\"outputs_lstm\"); OUT.mkdir(exist_ok=True, parents=True)\n",
        "model.save(OUT / \"lstm_url_classifier.h5\")\n",
        "\n",
        "# Save tokenizer\n",
        "with open(OUT / \"tokenizer_charlevel.json\", \"w\") as f:\n",
        "    f.write(tok.to_json())\n",
        "\n",
        "# Save metrics\n",
        "pd.DataFrame([{\n",
        "    \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1-score\": f1,\n",
        "    \"ROC-AUC\": auc,\n",
        "    \"Training Time (minutes)\": train_time_minutes,\n",
        "    \"Prediction Time (milliseconds)\": pred_time_ms_per_sample,\n",
        "    \"Maxlen\": maxlen, \"VocabSize\": vocab_size\n",
        "}]).to_csv(OUT / \"metrics_summary.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "qnAuOr7ZUX1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare With Researcher Model"
      ],
      "metadata": {
        "id": "9MZL9HN5UYw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RP = {\n",
        "    \"Accuracy\": 0.93,\n",
        "    \"Precision\": 0.87,\n",
        "    \"Recall\": 0.93,\n",
        "    \"F1-score\": 0.89,\n",
        "    \"Training Time (minutes)\": 2.64,\n",
        "    \"Prediction Time (milliseconds)\": 14.00\n",
        "}\n",
        "my_vals = [acc, prec, rec, f1, train_time_minutes, pred_time_ms_per_sample]\n",
        "rp_vals = [RP[\"Accuracy\"], RP[\"Precision\"], RP[\"Recall\"], RP[\"F1-score\"],\n",
        "           RP[\"Training Time (minutes)\"], RP[\"Prediction Time (milliseconds)\"]]\n",
        "titles = [\"Accuracy\",\"Precision\",\"Recall\",\n",
        "          \"F1-score\",\"Training Time (minutes)\",\"Prediction Time (milliseconds)\"]\n",
        "\n",
        "fig, axes = plt.subplots(2,3, figsize=(12,7)); axes = axes.ravel()\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.bar([\"My Model\",\"Researcher\"], [my_vals[i], rp_vals[i]])\n",
        "    ax.set_title(titles[i]); ax.set_xlabel(\"Model\")\n",
        "    if i <= 3:\n",
        "        ax.set_ylim(0, 1.05); ax.set_ylabel(titles[i])\n",
        "    elif i == 4:\n",
        "        ax.set_ylabel(\"Time (minutes)\")\n",
        "    else:\n",
        "        ax.set_ylabel(\"Time (milliseconds)\")\n",
        "    for j, v in enumerate([my_vals[i], rp_vals[i]]):\n",
        "        ax.text(j, v, f\"{v:.2f}\", ha=\"center\", va=\"bottom\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUT / \"comparison_bars.png\", dpi=180)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Saved model & files to: {OUT.resolve()}\")"
      ],
      "metadata": {
        "id": "zxQuZevMUY8f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}